name: Train ridge
description: train a Ridge regression with default parameters
inputs:
- {name: features, type: typing.Dict}
- {name: project_id, type: String}
- {name: model_repo, type: String}
outputs:
- {name: Output, type: typing.Dict}
implementation:
  container:
    image: python:3.7
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'google-cloud-storage' 'pandas' 'sklearn' 'np' || PIP_DISABLE_PIP_VERSION_CHECK=1
      python3 -m pip install --quiet --no-warn-script-location 'google-cloud-storage'
      'pandas' 'sklearn' 'np' --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - "def train_ridge (features, project_id, model_repo):\n    '''train a Ridge regression\
      \ with default parameters'''\n    import pandas as pd\n    import numpy as np\n\
      \    from sklearn.linear_model import Ridge\n    from sklearn.model_selection\
      \ import train_test_split\n    from sklearn.preprocessing import PowerTransformer\n\
      \    from sklearn.metrics import r2_score\n    from sklearn.metrics import mean_squared_error\n\
      \    from google.cloud import storage\n    import pickle\n    import json\n\
      \    import logging \n    import sys\n    import os\n\n    logging.basicConfig(stream=sys.stdout,\
      \ level=logging.INFO)\n\n    df = pd.DataFrame.from_dict(features)  \n\n   \
      \ logging.info(df.columns)\n\n    X = df.drop(['BodyFat', 'Density'], axis=1)\n\
      \    y = df['Density']\n\n    X['Bmi'] = 703 * X['Weight'] / (X['Height'] *\
      \ X['Height'])\n    X['ACratio'] = X['Abdomen'] / X['Chest']\n    X['HTratio']\
      \ = X['Hip'] / X['Thigh']\n    X.drop(['Weight', 'Height', 'Abdomen', 'Chest',\
      \ 'Hip', 'Thigh'], axis=1, inplace=True)\n\n    # Splitting the data for the\
      \ model\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n\
      \n    #Transformer\n    trans = PowerTransformer()\n    X_train = trans.fit_transform(X_train)\n\
      \    X_test = trans.transform(X_test)\n\n    # define and fit model\n    model\
      \ = Ridge()\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\
      \    # evaluate the model\n    r2 = r2_score(y_test, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_test,\
      \ y_pred))\n    ridge_metrics = {\n        \"R2\": r2,\n    #    \"RMSE\": rmse,\n\
      \    }\n    logging.info(ridge_metrics)\n\n    # Save the model localy\n   \
      \ local_file = '/tmp/local_model_ridge.pkl'\n    pickle.dump(model, open(local_file,\
      \ 'wb'))\n\n    #Save the transformer localy\n    local_file_trans = '/tmp/transformer.pkl'\n\
      \    pickle.dump(trans, open(local_file_trans, 'wb'))\n     # write out output\n\
      \n    # Save to GCS as model.pkl\n    client = storage.Client(project=project_id)\n\
      \    bucket = client.get_bucket(model_repo)\n    blob = bucket.blob('model_ridge.pkl')\n\
      \    blob_t = bucket.blob('transformer.pkl')\n    # Upload the locally saved\
      \ model\n    blob.upload_from_filename(local_file)\n    blob_t.upload_from_filename(local_file_trans)\n\
      \n    print(\"Saved the model to GCP bucket : \" + model_repo)\n    return ridge_metrics\n\
      \ndef _serialize_json(obj) -> str:\n    if isinstance(obj, str):\n        return\
      \ obj\n    import json\n\n    def default_serializer(obj):\n        if hasattr(obj,\
      \ 'to_struct'):\n            return obj.to_struct()\n        else:\n       \
      \     raise TypeError(\n                \"Object of type '%s' is not JSON serializable\
      \ and does not have .to_struct() method.\"\n                % obj.__class__.__name__)\n\
      \n    return json.dumps(obj, default=default_serializer, sort_keys=True)\n\n\
      import json\nimport argparse\n_parser = argparse.ArgumentParser(prog='Train\
      \ ridge', description='train a Ridge regression with default parameters')\n\
      _parser.add_argument(\"--features\", dest=\"features\", type=json.loads, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--project-id\", dest=\"\
      project_id\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --model-repo\", dest=\"model_repo\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str,\
      \ nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"\
      _output_paths\", [])\n\n_outputs = train_ridge(**_parsed_args)\n\n_outputs =\
      \ [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\n]\n\nimport\
      \ os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n\
      \    except OSError:\n        pass\n    with open(output_file, 'w') as f:\n\
      \        f.write(_output_serializers[idx](_outputs[idx]))\n"
    args:
    - --features
    - {inputValue: features}
    - --project-id
    - {inputValue: project_id}
    - --model-repo
    - {inputValue: model_repo}
    - '----output-paths'
    - {outputPath: Output}
